# How to avoid cascading failures in a distributed system ğŸ’£ğŸ’¥ğŸ”¥.

## Summary

Rate limiting is used in distributed systems to prevent cascading failures. By setting a limit on the number of requests a server can handle, the system can avoid overloading and crashing. Other strategies like job scheduling, batch processing, and approximate statistics can also help prevent system failures.

## Timestamped Highlights

0:00
ğŸ’£ Rate limiting is used to prevent cascading failures in distributed systems.

1:15
ğŸ’¥ Servers are load balanced to handle a range of requests, but if one server crashes, the others may become overwhelmed.

3:10
ğŸ”¥ Rate limiting involves setting a capacity for each server, and ignoring requests beyond that capacity to prevent overloading.

5:20
ğŸ’¥ Pre-scaling and auto-scaling are strategies to handle events or viral traffic, while rate limiting can still be used to manage the load.

7:05
ğŸ’¥ Job scheduling can be done in smaller chunks to avoid overwhelming the server with a large number of tasks.

9:45
ğŸ’¥ Batch processing and adding jitter can help manage the load of sending notifications to a large number of users.

11:45
ğŸ’¥ Caching, gradual deployments, and decoupling systems can improve performance and prevent system failures.

## Key Insights

- ğŸ’£ Cascading failures occur when one server crash leads to overwhelming load on other servers, eventually causing the entire system to crash.
- ğŸ’¥ Rate limiting is an effective strategy to prevent overwhelming servers by setting a capacity for each server and ignoring requests beyond that capacity.
- ğŸ”¥ Pre-scaling and auto-scaling can help handle events and viral traffic, while rate limiting can still be used to manage the load on individual servers.
- ğŸ’¥ Job scheduling can be done in smaller chunks to avoid overwhelming the server with a large number of tasks at once.
- ğŸ’¥ Batch processing and adding jitter can help manage the load of sending notifications to a large number of users, while approximate statistics can reduce the need for frequent database queries.
- ğŸ’¥ Caching, gradual deployments, and decoupling systems can improve performance and prevent system failures by reducing the load on servers and optimizing resource utilization.
