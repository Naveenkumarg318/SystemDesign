![image](https://github.com/Naveenkumarg318/SystemDesign/assets/143624407/66ad3837-d45e-4f60-90a4-31a774186d04)

**Load balancing distributes requests across servers.**

 You can use `hash(r_id) % n_servers` to get the server index for a request `r_id`.
 
-> Drawback: if you add an extra server `n_servers` changes and `r_id` will end up on a different server. This is bad because often we want to map requests with the same ids consistently to the same servers (there could e.g. be cached data there that we want to reuse).

 "Consistent hashing" hashes with a constant denominator `M`, e.g. `hash(r_id) % M`, and then maps the resulting integer onto a server index. Each server has a range of integers that map to their index.

Consistent hashing in load balancing is a method where we assign items (like data or tasks) and servers on a circle. When something new comes in, it goes to the closest server on the circle, simplifying the process. Adding or removing servers doesn't mess up everything, making the system easy to manage and adaptable. It's like organizing things in a circle for efficient handling without too much fuss.

Let me clarify. In consistent hashing, when I mention the "closest server," it doesn't mean physical proximity but rather the next server in a virtual ring or circle. Each server is assigned a range on this circle, and when a request comes in, it gets directed to the server whose range immediately follows the hashed value of the request in a clockwise direction.

This method helps in balancing the load because the "closeness" is determined by the hash value, not the physical or computational capacity of the server. When servers are evenly distributed around the circle, the load tends to be balanced because each server is responsible for a certain range of hash values. If you add or remove a server, only a portion of the workload is affected, allowing for a more even distribution of requests across the available servers.

---------------------------------------------------------------------------------------------


 The pie example demonstrates, that if an extra server is added, the hashing function stays the same, and one can then change the range-to-server-index mapping slightly so that it remains likely that an `r_id` gets mapped to the same server as before the server addition.

 ## Incase if you are confused about the pie chart explaination here's a simple breakdown of it.

**We need to reduce the distribution from 25 each to 20 each. So we take 5 from the first server and merge it with the second one. Then we take 10(5 from the first one and 5 from the second one) and merge it with third. So now, both one and two have 20 each. Then we go on taking 15 from third and merging it with fourth and finally, taking 20 from four to create the fifth server's space.**

### Further explanation:

1. Suppose you're serving users 1 to 20 on S0, 21-40 on S2 and so on. If you insert or remove a server, each server will have to adjust in a way so that load is balanced. 

2. Now, suppose S1 is dropping 5 users, and these requests are now being routed to server Sn. 

3. Each server has some local data, cache, etc. for the users/requests it's been serving, and migrating all these is costly. The "buckets" here are basically the operations involved during these kind of migrations.

